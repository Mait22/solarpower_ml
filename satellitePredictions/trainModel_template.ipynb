{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d1a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions to load data\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74a65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Function for loading the satellite images\n",
    "Arguments:\n",
    " selectedDataset - can be \"2019-07\" - e.g. specific month\n",
    "                          \"\" - all months\n",
    " pictureTypes - list defining what sort of constellations are loaded\n",
    "                \"dnc\" - \n",
    "                \"dnm\" - 24-hour Microphysics RGB\n",
    "\n",
    " pictureSize - Size to resize images to after they are read from disk. Defaults to (256, 256).\n",
    "Returns:\n",
    "  2 dictionaries\n",
    "  dates - dates corresponding to pictures\n",
    "  pictures - satellite pictures\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def loadSatelliteImages(selectedDatasets=[\"2019-07\"], pictureTypes=[\"dnc\", \"dnm\"], pictureSize=(256, 256)):\n",
    "    pictures = defaultdict(lambda: defaultdict(list))\n",
    "    dates = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for selectedDataset in selectedDatasets:\n",
    "        for pictureType in pictureTypes:\n",
    "            satellitePictureNames = os.listdir(os.path.join(\".\", \"data\", selectedDataset, pictureType))\n",
    "\n",
    "            for satellitePictureName in satellitePictureNames:\n",
    "                # Load image\n",
    "                imageDateStr = satellitePictureName.replace(\"dnc-\", \"\").replace(\"dnm-\", \"\").replace(\".png\", \"\")\n",
    "                #Parse date to datetime 2019-07-01-05-45\n",
    "                imageDate = datetime.strptime(imageDateStr, \"%Y-%m-%d-%H-%M\")\n",
    "                img = image.load_img(os.path.join(\".\", \"data\", selectedDataset,\n",
    "                                                  pictureType, satellitePictureName),\n",
    "                                     target_size=pictureSize)\n",
    "                # Convert to np array and add to list\n",
    "                pictures[selectedDataset][pictureType].append(np.array(img))\n",
    "                dates[selectedDataset][pictureType].append(imageDate)\n",
    "            dates[selectedDataset][pictureType] = np.array(dates[selectedDataset][pictureType])\n",
    "            pictures[selectedDataset][pictureType] = np.array(pictures[selectedDataset][pictureType])\n",
    "            #Argsort\n",
    "            sortedDates = np.argsort(dates[selectedDataset][pictureType])\n",
    "            dates[selectedDataset][pictureType] = dates[selectedDataset][pictureType][sortedDates]\n",
    "            pictures[selectedDataset][pictureType] = pictures[selectedDataset][pictureType][sortedDates]\n",
    "\n",
    "    return pictures, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a491f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "npixel = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142544da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sat, labels = loadSatelliteImages(selectedDatasets=[\"2019-07\", \"2019-08\", \"2019-09\"], pictureTypes=[\"dnc\"], pictureSize=(npixel, npixel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63cd9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(sat[\"2019-07\"][\"dnc\"][30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e5263",
   "metadata": {},
   "source": [
    "## Transforming images to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adffb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function for creating samples out of satellite data. Each row of X contains given number \n",
    "(imagesInSample) used to predict future weather. Rows of y are similar to y, although shifted\n",
    "by one time interval\n",
    "\n",
    "Arguments\n",
    "dataDict - dictionary, which contains image data\n",
    "X_imagetype - the type of images that are requested for X\n",
    "Y_imagetype - the type of images that are requested for y\n",
    "imagesInSample - number of images in data row\n",
    "\"\"\"\n",
    "def createDataSetFromImages(dataDict, X_imagetype, Y_imagetype, selectChannelX=None, selectChannelY=None, imagesInSample=6):\n",
    "    X = []\n",
    "    y = []\n",
    "    for month in dataDict.keys():\n",
    "        if selectChannelX is None:\n",
    "            X_subset = dataDict[month][X_imagetype]\n",
    "        else:\n",
    "            X_subset = dataDict[month][X_imagetype][:,:,:,selectChannelX]\n",
    "            # Add a channel dimension if using only one channel\n",
    "            X_subset = np.expand_dims(X_subset, axis=-1)\n",
    "\n",
    "        if selectChannelY is None:\n",
    "            y_subset = dataDict[month][Y_imagetype]\n",
    "        else:\n",
    "            y_subset = dataDict[month][Y_imagetype][:,:,:,selectChannelY]\n",
    "            y_subset = np.expand_dims(y_subset, axis=-1)\n",
    "        assert len(X_subset)==len(y_subset) # Lengths must match\n",
    "        for i in range(0, len(X_subset)-imagesInSample-1):\n",
    "            #Select images so that y is shifted by one frame\n",
    "            selected_X = X_subset[i:i+imagesInSample]\n",
    "            selected_y = y_subset[i+1:i+1+imagesInSample]\n",
    "            X.append(selected_X)\n",
    "            y.append(selected_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9253737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to the 0-1 range.\n",
    "for dataSet in sat.keys():\n",
    "    for pictureType in sat[dataSet].keys():\n",
    "        sat[dataSet][pictureType] = sat[dataSet][pictureType] / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086d715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = createDataSetFromImages(sat, \"dnc\", \"dnc\", 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa16856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that shift is OK, following value must be 0:0.0\n",
      "Check that shift is OK, following value must be 0:0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check that shift is OK, following value must be 0:{np.sum(y[-1][0]-X[-1][1])}\")\n",
    "print(f\"Check that shift is OK, following value must be 0:{np.sum(y[0][0]-X[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc84987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split into train and validation sets\n",
    "indexes = np.arange(X.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * X.shape[0])]\n",
    "val_index = indexes[int(0.9 * X.shape[0]) :]\n",
    "train_X = X[train_index]\n",
    "train_y = y[train_index]\n",
    "val_X = X[val_index]\n",
    "val_y = y[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc64eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that shift is OK, following value must be 0:0.0\n",
      "Check that shift is OK, following value must be 0:0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check that shift is OK, following value must be 0:{np.sum(val_y[-1][0]-val_X[-1][1])}\")\n",
    "print(f\"Check that shift is OK, following value must be 0:{np.sum(val_y[0][0]-val_X[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac9c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shapes: (7929, 6, 128, 128, 1), (7929, 6, 128, 128, 1)\n",
      "Validation Dataset Shapes: (881, 6, 128, 128, 1), (881, 6, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Check that dims match\n",
    "print(\"Training Dataset Shapes: \" + str(train_X.shape) + \", \" + str(train_y.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(val_X.shape) + \", \" + str(val_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad8990",
   "metadata": {},
   "source": [
    "# Start building model\n",
    "\n",
    "#### https://keras.io/examples/vision/conv_lstm/\n",
    "\n",
    "#### https://github.com/xibinyue/ConvLSTM-1/blob/master/radar_forecast.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e146a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218d62b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 20:50:38.336219: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-23 20:50:38.338950: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Construct the input layer with no definite frame size.\n",
    "inp = layers.Input(shape=(None, *train_X.shape[2:]))\n",
    "\n",
    "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(inp)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = layers.Conv3D(\n",
    "    filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    ")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52e7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = keras.models.Model(inp, x)\n",
    "model.compile(\n",
    "    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92de7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 128, 128, 1 0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, None, 128, 128, 64 416256    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 128, 128, 64 256       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, 128, 128, 64 295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 128, 128, 64 256       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, None, 128, 128, 64 33024     \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, None, 128, 128, 1) 1729      \n",
      "=================================================================\n",
      "Total params: 746,689\n",
      "Trainable params: 746,433\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaecbdb",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04e3817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 20:50:56.652960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   3/1069 [..............................] - ETA: 3:38:19 - loss: 0.6143"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_451419/3904682669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/metsat/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 20\n",
    "batch_size = 5\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_X, val_y),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aed3d377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 16:23:32.043593: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('savedModel_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
