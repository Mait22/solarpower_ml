{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This model here is trained on 4 selected weather stations to predict one given weather station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and converting to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import datetime\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar intensity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load initial data\n",
    "hourly_sun_intensity = pd.read_excel('2-10_21_524-2 Andmed.xlsx', sheet_name = 'tunni sum.kiirgus', header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names by shortening them and converting to English\n",
    "newColumnNames = dict()\n",
    "newColumnNames[\"Aasta\"] = \"y\"\n",
    "newColumnNames[\"Kuu\"] = \"m\"\n",
    "newColumnNames[\"Päaev\"] = \"d\"\n",
    "newColumnNames[\"Kell (UTC)\"] = \"time\"\n",
    "for columnName in hourly_sun_intensity.columns:\n",
    "    if \"kiirgus\" in columnName:\n",
    "        newColumnNames[columnName] = \"solar_\"+columnName.replace(\" summaarne kiirgus, W/m²\", \"\")\n",
    "#newColumnNames = [\"y\", \"m\", \"d\", \"time\"]+[\"solar_\"+columnName.replace(\" summaarne kiirgus, W/m²\", \"\") for columnName in hourly_sun_intensity.columns if \"kiirgus\" in columnName]\n",
    "hourly_sun_intensity = hourly_sun_intensity.rename(columns=newColumnNames)\n",
    "#hourly_sun_intensity.columns = newColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some weather stations have changed locations over time, as the differences between their locations are rather small (less than 8 km)\n",
    "# We at first do not make separation between them\n",
    "\n",
    "def join_columns(c1, c2, nc, df, column_id): # Function for joining columns, where an area has two weather measuring points\n",
    "    data = []\n",
    "    cs = [c1, c2]\n",
    "    for i, rows in df[cs].iterrows():\n",
    "        if (pd.isna(rows[0]) == True) & (pd.isna(rows[1]) == False):\n",
    "            data.append(round(rows[1], 2))\n",
    "        elif (pd.isna(rows[0]) == False) & (pd.isna(rows[1]) == True):\n",
    "            data.append(round(rows[0], 2))\n",
    "        elif (pd.isna(rows[0]) == False) & (pd.isna(rows[1]) == False):\n",
    "            data.append(round(rows.mean(), 2))\n",
    "        elif (pd.isna(rows[0]) == True) & (pd.isna(rows[1]) == True):\n",
    "            data.append(rows[0])\n",
    "\n",
    "    df = df.drop(columns = [c1, c2])\n",
    "    df.insert(column_id, nc, data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge columns, which are due to weather station moving\n",
    "hourly_sun_intensity = join_columns('solar_Narva', 'solar_Narva-Jõesuu', 'solar_Narva', hourly_sun_intensity, 4)\n",
    "hourly_sun_intensity = join_columns('solar_Pärnu-Sauga', 'solar_Pärnu', 'solar_Pärnu', hourly_sun_intensity, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where some value is missing\n",
    "hourly_sun_intensity = hourly_sun_intensity.dropna()\n",
    "#If value is -1 it corresponds to night, set it to 0\n",
    "hourly_sun_intensity = hourly_sun_intensity.replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift the times -X minutes to facilitate predicting future solar intensity from existing\n",
    "def shiftDateTime(df, numberOfHours):\n",
    "    dateTimes = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        dateTimes+=[datetime.datetime.combine(datetime.date(row.y, row.m, row.d), row.time)+datetime.timedelta(hours=numberOfHours)]\n",
    "    df2 = copy.deepcopy(df)\n",
    "    df2[\"y\"] = [date.year for date in dateTimes]\n",
    "    df2[\"m\"] = [date.month for date in dateTimes]\n",
    "    df2[\"d\"] = [date.day for date in dateTimes]\n",
    "    df2[\"time\"] = [date.time() for date in dateTimes]\n",
    "    \n",
    "    return df2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_sun_intensity_Shifted = shiftDateTime(hourly_sun_intensity, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from different weather stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locations\n",
    "\n",
    "\n",
    "Tallinn-Harku\n",
    "Laius: N 59°23´53´´\n",
    "Pikkus: E 24°36´10´´\n",
    "Decimal\n",
    "Lat: 59.398055\n",
    "Long: 24.602778\n",
    "\n",
    "\n",
    "Haapsalu meteoroloogiajaam\n",
    "Laius N 58°56´40´´\n",
    "Pikkus E 23°33´18´´\n",
    "Decimal\n",
    "Lat: 58.944444\n",
    "Long: 23.555\n",
    "\n",
    "Narva\n",
    "Laius: N 59°23´22´´\n",
    "Pikkus: E 28°06´33´´\n",
    "Decimal\n",
    "Lat: 59.389444\n",
    "Long: 28.109167\n",
    "\n",
    "Pärnu\n",
    "Laius: N 58°23´4,44´´\n",
    "Pikkus: E 24°29´6,71´´\n",
    "Decimal\n",
    "Lat: 58.384556\n",
    "Long: 24.485197\n",
    "\n",
    "Roomassaare\n",
    "Laius: N 58°13’05”\n",
    "Pikkus: E 22°30’23”\n",
    "Decimal\n",
    "Lat: 58.218056 \n",
    "Long: 22.506389 \n",
    "\n",
    "Tartu-Tõravere meteoroloogiajaam\n",
    "Laius: N 58°15´51´´\n",
    "Pikkus: E 26°27´41´\n",
    "Decimal\n",
    "Lat: 58.264167\n",
    "Long: 26.461389\n",
    "\n",
    "Tiirikoja järvejaam\n",
    "Laius: N 58°51´55´´\n",
    "Pikkus: E 26°57´08´´\n",
    "Decimal\n",
    "Lat: 58.865278\n",
    "Long: 26.952222\n",
    "\n",
    "Vilsandi rannikujaam\n",
    "Laius: N 58°22´58”\n",
    "Pikkus: E 21°48´51”\n",
    "Deciaml\n",
    "Lat: 58.382778\n",
    "Long: 21.814167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_coordinates = dict()\n",
    "weather_station_coordinates[\"tallinn\"] = [59.398055, 24.602778]\n",
    "weather_station_coordinates[\"haapsalu\"] = [58.944444, 23.555]\n",
    "weather_station_coordinates[\"narva\"] = [59.389444, 28.109167]\n",
    "weather_station_coordinates[\"parnu\"] = [59.389444, 28.109167]\n",
    "weather_station_coordinates[\"roomassaare\"] = [58.218056, 22.506389]\n",
    "weather_station_coordinates[\"tartu\"] = [58.264167, 26.461389]\n",
    "weather_station_coordinates[\"tiirikoja\"] = [58.865278, 26.952222]\n",
    "weather_station_coordinates[\"vilsandi\"] = [58.382778, 21.814167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedColumns = [\"Aasta\", \"Kuu\", \"Päev\", \"Kell (UTC)\", \"Õhutemperatuur °C\",\"Suhteline õhuniiskus %\", \"10 minuti keskmine tuule kiirus m/s\", \"10 minuti keskmine tuule suund\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names by shortening them and converting to English\n",
    "\n",
    "def updateColumnNames(df, location):\n",
    "    newColumnNames = dict()\n",
    "    newColumnNames[\"Aasta\"] = \"y\"\n",
    "    newColumnNames[\"Kuu\"] = \"m\"\n",
    "    newColumnNames[\"Päev\"] = \"d\"\n",
    "    newColumnNames[\"Kell (UTC)\"] = \"time\"\n",
    "    newColumnNames[\"Õhutemperatuur °C\"] = f\"temp_{location}\"\n",
    "    newColumnNames[\"10 minuti keskmine tuule kiirus m/s\"] = f\"wind_speed_{location}\"\n",
    "    newColumnNames[\"Õhurõhk jaama kõrgusel hPa\"] = f\"pressure_{location}\"\n",
    "    newColumnNames[\"Suhteline õhuniiskus %\"] = f\"rel_humidity_{location}\"\n",
    "    newColumnNames[\"10 minuti keskmine tuule suund\"] = f\"wind_dir_{location}\"\n",
    "    df = df.rename(columns=newColumnNames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFromXlsx(filename, columns, location):\n",
    "    #Load xlsx\n",
    "    df = pd.read_excel(filename, header = 1)\n",
    "    df = df[columns]\n",
    "    #Drop rows where data is missing\n",
    "    #df = df.dropna()\n",
    "    #Update column names for clarity\n",
    "    df = updateColumnNames(df, location)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Tallinn\n",
    "data_tallinn = getFromXlsx(\"./data/Tallinn-Harku_2004-2020.xlsx\", selectedColumns, \"tallinn\")\n",
    "#data_tallinn[\"lat_tallinn\"] = len(data_tallinn)*[weather_station_coordinates[\"tallinn\"][0]]\n",
    "#data_tallinn[\"long_tallinn\"] = len(data_tallinn)*[weather_station_coordinates[\"tallinn\"][1]]\n",
    "#Get Roomassaare\n",
    "data_roomassaare = getFromXlsx(\"./data/Roomassaare_2008-2020.xlsx\", selectedColumns, \"roomassaare\")\n",
    "#data_roomassaare[\"lat_roomassaare\"] = len(data_roomassaare)*[weather_station_coordinates[\"roomassaare\"][0]]\n",
    "#data_roomassaare[\"long_roomassaare\"] = len(data_roomassaare)*[weather_station_coordinates[\"roomassaare\"][1]]\n",
    "#Merge tables\n",
    "data_weather = data_tallinn.merge(data_roomassaare, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Vilsandi\n",
    "data_vilsandi = getFromXlsx(\"./data/Vilsandi_2004-2020.xlsx\", selectedColumns, \"vilsandi\")\n",
    "#data_vilsandi[\"lat_vilsandi\"] = len(data_vilsandi)*[weather_station_coordinates[\"vilsandi\"][0]]\n",
    "#data_vilsandi[\"long_vilsandi\"] = len(data_vilsandi)*[weather_station_coordinates[\"vilsandi\"][1]]\n",
    "#Merge tables\n",
    "data_weather = data_weather.merge(data_vilsandi, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Parnu\n",
    "#data_parnu1 = getFromXlsx(\"./data/Parnu-Sauga_01.12.2004-31.03.2019.xlsx\", selectedColumns, \"parnu\")\n",
    "#data_parnu2 = getFromXlsx(\"./data/Parnu_01.04.2019-2020.xlsx\", selectedColumns, \"parnu\")\n",
    "#data_parnu = data_parnu1.append(data_parnu2)\n",
    "\n",
    "##Merge tables\n",
    "#data_weather = data_weather.merge(data_parnu, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Tartu = getFromXlsx(\"./data/Tartu-Toravere_2004-2020.xlsx\", selectedColumns, \"tartu\")\n",
    "#data_Tartu[\"lat_tartu\"] = len(data_Tartu)*[weather_station_coordinates[\"tartu\"][0]]\n",
    "#data_Tartu[\"long_tartu\"] = len(data_Tartu)*[weather_station_coordinates[\"tartu\"][1]]\n",
    "#Merge tables\n",
    "\n",
    "data_weather = data_weather.merge(data_Tartu, how='left', on=[\"y\", \"m\", \"d\", \"time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Narva = getFromXlsx(\"./data/Narva_19.12.2013-2020.xlsx\", selectedColumns, \"narva\")\n",
    "data_weather = data_weather.merge(data_Narva, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again drop all rows where some row is missing\n",
    "data_weather = data_weather.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join weather and solar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_solar_weather = hourly_sun_intensity_Shifted.merge(data_weather, how='left', on=[\"y\", \"m\", \"d\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = []\n",
    "for i in range(len(data_solar_weather)):\n",
    "    hours+=[data_solar_weather.iloc[i].time.hour]\n",
    "data_solar_weather[\"h\"] = hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_solar_weather = data_solar_weather.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'm', 'd', 'time', 'solar_Narva', 'solar_Pärnu', 'solar_Haapsalu',\n",
       "       'solar_Tallinn-Harku', 'solar_Roomassaare', 'solar_Tartu-Tõravere',\n",
       "       'solar_Tiirikoja', 'solar_Vilsandi', 'temp_tallinn',\n",
       "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
       "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
       "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
       "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
       "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
       "       'wind_dir_tartu', 'temp_narva', 'rel_humidity_narva',\n",
       "       'wind_speed_narva', 'wind_dir_narva', 'h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solar_weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, predict Tallinn using Tallinn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn']]\n",
    "\n",
    "y = data_solar_weather[['solar_Tallinn-Harku']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.12577897000247"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# squared = False returns RMSE, otherwise MSE\n",
    "mean_squared_error(y_test, dtr.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.01107241412734"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.84158218583287"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2, predict Pärnu using Talinn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.23589459344848"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# squared = False returns RMSE, otherwise MSE\n",
    "mean_squared_error(y_test, dtr.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.36021142195774"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.9543162945638"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 other stations, predict Pärnu, different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Stations Tartu, Tallinn, Roomassaare, Vilsandi, predict Pärnu\n",
    "dtr 96.26316991627043\n",
    "rf 66.69709972042308\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'm', 'd', 'time', 'solar_Narva', 'solar_Pärnu', 'solar_Haapsalu',\n",
       "       'solar_Tallinn-Harku', 'solar_Roomassaare', 'solar_Tartu-Tõravere',\n",
       "       'solar_Tiirikoja', 'solar_Vilsandi', 'temp_tallinn',\n",
       "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
       "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
       "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
       "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
       "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
       "       'wind_dir_tartu', 'temp_narva', 'rel_humidity_narva',\n",
       "       'wind_speed_narva', 'wind_dir_narva', 'h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_solar_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'rel_humidity_tallinn', 'wind_speed_tallinn', 'wind_dir_tallinn',\n",
    "       'temp_roomassaare', 'rel_humidity_roomassaare',\n",
    "       'wind_speed_roomassaare', 'wind_dir_roomassaare', 'temp_vilsandi',\n",
    "       'rel_humidity_vilsandi', 'wind_speed_vilsandi', 'wind_dir_vilsandi',\n",
    "       'temp_tartu', 'rel_humidity_tartu', 'wind_speed_tartu',\n",
    "       'wind_dir_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# squared = False returns RMSE, otherwise MSE\n",
    "mean_squared_error(y_test, dtr.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5 Stations Tartu, Tallinn, Roomassaare, Vilsandi, Narva, predict Pärnu\n",
    "dtr \n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.30923244650441"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, dtr.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.99407415307772"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "############### Random Forest ##############################\n",
    "\n",
    "n_estimatorss = [100]\n",
    "max_depths=[20]\n",
    "min_samples_splits=[4,6,8,16]\n",
    "seeds = [1]\n",
    "results_df = pd.DataFrame(columns=['model',\"seed\",\"n_estimators\",\"max_depth\",\"min_samples_split\",'TrainError', 'ValError', 'deltaErrors'])\n",
    "for seed in seeds:\n",
    "    for n_estimator in n_estimatorss:\n",
    "        for max_d in max_depths:\n",
    "            for min_ss in min_samples_splits:\n",
    "                rf = RandomForestRegressor(criterion=\"squared_error\", n_estimators=n_estimator, max_depth=max_d, min_samples_split=min_ss, random_state=seed).fit(X_train, y_train)\n",
    "                trainError = mean_squared_error(y_train, rf.predict(X_train), squared = False)\n",
    "                valError = mean_squared_error(y_test, rf.predict(X_test), squared = False)\n",
    "                results_df = results_df.append({'model': 'RF',\"seed\":seed,\"n_estimators\":n_estimator,\"max_depth\":max_d,\"min_samples_split\":min_ss,\"TrainError\":trainError, 'ValError':valError, 'deltaErrors':abs(trainError-valError)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>30.873757</td>\n",
       "      <td>67.119425</td>\n",
       "      <td>36.245668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>33.273907</td>\n",
       "      <td>67.285888</td>\n",
       "      <td>34.011981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>35.777680</td>\n",
       "      <td>67.457766</td>\n",
       "      <td>31.680086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>44.046657</td>\n",
       "      <td>68.225880</td>\n",
       "      <td>24.179223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model seed n_estimators max_depth min_samples_split  TrainError   ValError  \\\n",
       "0    RF    1          100        20                 4   30.873757  67.119425   \n",
       "1    RF    1          100        20                 6   33.273907  67.285888   \n",
       "2    RF    1          100        20                 8   35.777680  67.457766   \n",
       "3    RF    1          100        20                16   44.046657  68.225880   \n",
       "\n",
       "   deltaErrors  \n",
       "0    36.245668  \n",
       "1    34.011981  \n",
       "2    31.680086  \n",
       "3    24.179223  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"ValError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>30.61484</td>\n",
       "      <td>66.889728</td>\n",
       "      <td>36.274888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model seed n_estimators max_depth min_samples_split  TrainError   ValError  \\\n",
       "0    RF    1          200        20                 4    30.61484  66.889728   \n",
       "\n",
       "   deltaErrors  \n",
       "0    36.274888  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"deltaErrors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>36.957563</td>\n",
       "      <td>74.915639</td>\n",
       "      <td>37.958076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>36.956893</td>\n",
       "      <td>74.917349</td>\n",
       "      <td>37.960456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>29.717919</td>\n",
       "      <td>74.207728</td>\n",
       "      <td>44.489809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>29.719276</td>\n",
       "      <td>74.211733</td>\n",
       "      <td>44.492457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model seed n_estimators max_depth min_samples_split  TrainError   ValError  \\\n",
       "5     RF    1          100        40                 8   36.957563  74.915639   \n",
       "8     RF    1          100        50                 8   36.956893  74.917349   \n",
       "14    RF    1          100        70                 8   36.956893  74.917349   \n",
       "11    RF    1          100        60                 8   36.956893  74.917349   \n",
       "17    RF    1          100        80                 8   36.956893  74.917349   \n",
       "..   ...  ...          ...       ...               ...         ...        ...   \n",
       "33    RF    1          200        80                 4   29.717919  74.207728   \n",
       "30    RF    1          200        70                 4   29.717919  74.207728   \n",
       "27    RF    1          200        60                 4   29.717919  74.207728   \n",
       "24    RF    1          200        50                 4   29.717919  74.207728   \n",
       "21    RF    1          200        40                 4   29.719276  74.211733   \n",
       "\n",
       "    deltaErrors  \n",
       "5     37.958076  \n",
       "8     37.960456  \n",
       "14    37.960456  \n",
       "11    37.960456  \n",
       "17    37.960456  \n",
       "..          ...  \n",
       "33    44.489809  \n",
       "30    44.489809  \n",
       "27    44.489809  \n",
       "24    44.489809  \n",
       "21    44.492457  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"deltaErrors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  \"Since version 1.0, \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(max_depth=10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "gbr = HistGradientBoostingRegressor(max_iter=100, max_depth=10)\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Pärnu, use 4 stations, use only one type of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h', 'temp_tallinn',\n",
    "       'temp_roomassaare', 'temp_vilsandi',\n",
    "       'temp_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=80)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.92307200732515"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, dtr.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.96527929643392"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.86844172490507"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_solar_weather[['m','d', 'h',\n",
    "       'rel_humidity_tallinn', 'rel_humidity_roomassaare',\n",
    "       'rel_humidity_vilsandi', 'rel_humidity_tartu']]\n",
    "\n",
    "y = data_solar_weather[['solar_Pärnu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.89287296065847"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr= DecisionTreeRegressor(max_depth = 80)\n",
    "dtr.fit(X_train, y_train)\n",
    "dtr.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, dtr.predict(X_test_scaled), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.07701172527304"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf= RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of trying Stacking to see if it works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
